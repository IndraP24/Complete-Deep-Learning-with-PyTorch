{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification using PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional.classification.accuracy import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PyTroch Lightning\n",
    "\n",
    "1. model\n",
    "2. optimizer \n",
    "3. data\n",
    "4. training loop - The Magic\n",
    "5. validation loop - The Validation Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ResNet as a Lightning Module\n",
    "class ResNet(pl.LightningModule): # --> Model with residual connections\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(28 * 28, 64)\n",
    "        self.l2 = nn.Linear(64, 64)\n",
    "        self.l3 = nn.Linear(64, 10)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h1 = nn.functional.relu(self.l1(x))\n",
    "        h2 = nn.functional.relu(self.l2(h1))\n",
    "        do = self.do(h2 + h1)\n",
    "        logits = self.l3(do)\n",
    "        return logits\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.SGD(self.parameters(), lr=1e-2)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        # x: b * 1 * 28 * 28\n",
    "        b = x.size(0)\n",
    "        x = x.view(b, -1)\n",
    "\n",
    "        # 1: Forward Prop\n",
    "        logits = self(x)\n",
    "\n",
    "        # 2: Compute Objective / Loss Function\n",
    "        J = self.loss(logits, y)\n",
    "\n",
    "        acc = accuracy(logits, y)\n",
    "        self.log(\"acc\", acc, prog_bar=True)\n",
    "        return {'loss': J, \"acc\": acc}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        results = self.training_step(batch, batch_idx)\n",
    "        return results\n",
    "    \n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        avg_val_loss = torch.tensor([x['loss'] for x in val_step_outputs]).mean()\n",
    "        avg_val_acc = torch.tensor([x['acc'] for x in val_step_outputs]).mean()\n",
    "\n",
    "        return {'val_loss': avg_val_loss, \"val_acc\": avg_val_acc}\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        # Train, val split\n",
    "        train_data = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "        # train, val = random_split(train_data, [55000, 5000])\n",
    "        train_loader = DataLoader(train_data, batch_size=64, num_workers=8)\n",
    "        # val_loader = DataLoader(val, batch_size=32)\n",
    "        return train_loader\n",
    "\n",
    "model = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/indrap24/anaconda3/envs/ptDL-39/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:101: UserWarning: you defined a validation_step but have no val_dataloader. Skipping val loop\n",
      "  rank_zero_warn(f\"you defined a {step_name} but have no {loader_name}. Skipping {stage} loop\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type             | Params\n",
      "------------------------------------------\n",
      "0 | l1   | Linear           | 50.2 K\n",
      "1 | l2   | Linear           | 4.2 K \n",
      "2 | l3   | Linear           | 650   \n",
      "3 | do   | Dropout          | 0     \n",
      "4 | loss | CrossEntropyLoss | 0     \n",
      "------------------------------------------\n",
      "55.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.1 K    Total params\n",
      "0.220     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indrap24/anaconda3/envs/ptDL-39/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  41%|████      | 381/938 [00:08<00:12, 43.35it/s, loss=0.338, v_num=9, acc=0.922]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indrap24/anaconda3/envs/ptDL-39/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1051: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  41%|████      | 381/938 [00:21<00:32, 17.37it/s, loss=0.338, v_num=9, acc=0.922]"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=5, gpus=1)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9bc8a72d961133e51c159ac9d943613f233897aed07edd92e91710696a38f937"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('ptDL-39': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
